{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc88411",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **Corto #8**\n",
    "\n",
    "### _análisis de los programas_\n",
    "\n",
    "Link al Repo Para Ver Todos los Archivos, Incluyendo los Originales .c: https://github.com/sofigo1010/trex-python\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Cambios hechos al código original\n",
    "\n",
    "### 1.1 Parámetros de entrada (carga de trabajo)\n",
    "- **Aumentamos el tamaño del input** para provocar trabajo suficiente y observar diferencias claras entre la versión secuencial y la paralela:\n",
    "  - `N_FRAMES = 1000`\n",
    "  - `N_OBS    = 200000`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51bf38",
   "metadata": {},
   "source": [
    "# Informe de rendimiento inicial con el aumento de inputs de secuencial.c vs paralelizado.c original\n",
    "\n",
    "**Archivos de resultados:**  \n",
    "- `original-code/par.log` (paralelo)  \n",
    "- `original-code/sec.log` (secuencial)\n",
    "\n",
    "## Resumen de métricas\n",
    "\n",
    "| Versión     | Tiempo total (ms) | Colisiones |\n",
    "|-------------|-------------------:|-----------:|\n",
    "| Paralelo    |            48.709  |        673 | \n",
    "| Secuencial  |           423.622  |        698 | \n",
    "\n",
    "**Speedup (aceleración):**  \n",
    "$$\n",
    "S \\;=\\; \\frac{T_{\\text{sec}}}{T_{\\text{par}}}\n",
    "\\;=\\;\n",
    "\\frac{423.622}{48.709}\n",
    "\\;\\approx\\;\n",
    "8.70\\times\n",
    "$$\n",
    "\n",
    "**Reducción relativa de tiempo:**  \n",
    "$$\n",
    "\\Delta\\% \\;=\\; \\left(1 - \\frac{T_{\\text{par}}}{T_{\\text{sec}}}\\right)\\times 100\n",
    "\\;=\\;\n",
    "\\left(1 - \\frac{48.709}{423.622}\\right)\\times 100\n",
    "\\;\\approx\\;\n",
    "88.51\\%\n",
    "$$\n",
    "\n",
    "## Análisis\n",
    "\n",
    "### 1) Rendimiento (tiempo)\n",
    "- **El paralelo es ~8.70× más rápido** en tiempo de pared: 48.709 ms vs 423.622 ms.  \n",
    "- La mejora es **sustancial** y típica cuando la parte dominante del trabajo es paralelizable y el overhead de hilos queda amortizado.\n",
    "\n",
    "\n",
    "### 2) Sobre el número de iteraciones y su efecto\n",
    "- **Más iteraciones totales** (trabajo) suelen **mejorar el speedup observado** porque:\n",
    "  - Amortizan mejor el **overhead** de creación/sincronización de hilos.\n",
    "  - Aumentan la **fracción paralelizable efectiva**, haciendo que el término serial pese menos (intuición de la Ley de Amdahl).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colisiones totales: 689\n",
      "RESULTADO: MUERE\n",
      "Tiempo total simulacion: 117.746 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Limita hilos internos de NumPy/BLAS: aseguramos usar exactamente 3 threads (los nuestros).\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"BLIS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, TextIO, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "FPS = 60\n",
    "DT = 1.0 / FPS\n",
    "\n",
    "@dataclass\n",
    "class Player:\n",
    "    x: float = 5.0\n",
    "    y: float = 0.0\n",
    "\n",
    "def now_ms() -> float:\n",
    "    return time.perf_counter() * 1000.0\n",
    "\n",
    "def render_scene(frame: int, p: Player, x_curr: np.ndarray, out: Optional[TextIO] = None) -> None:\n",
    "    \"\"\"Salida estilo C; lee obs0 del buffer de lectura (x_curr).\"\"\"\n",
    "    line = f\"frame={frame}  player.y={p.y:.2f}  obs0.x={x_curr[0]: .2f}\\n\"\n",
    "    if out:\n",
    "        out.write(line)\n",
    "    else:\n",
    "        # print(line, end=\"\")\n",
    "        pass\n",
    "\n",
    "\n",
    "def update_obstacles(x_src: np.ndarray, v: np.ndarray, dt: float, x_dst: np.ndarray) -> None:\n",
    "    np.add(x_src, v * dt, out=x_dst)\n",
    "\n",
    "def collisions_count(x_curr: np.ndarray, p: Player) -> int:\n",
    "    if p.y >= 1.0:\n",
    "        return 0\n",
    "    return int(np.count_nonzero(np.abs(x_curr - p.x) <= 1.0))\n",
    "\n",
    "def simulate_parallel(\n",
    "    x0: np.ndarray,\n",
    "    v: np.ndarray,\n",
    "    n_frames: int = 1000,\n",
    "    jump_h: float = 1.2,\n",
    "    p_jump: float = 0.25,\n",
    "    seed: int = 123,\n",
    "    log_path: Optional[str] = \"par_python.log\",   \n",
    ") -> Tuple[int, float]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    x_curr = x0.copy()\n",
    "    x_next = np.empty_like(x_curr)\n",
    "\n",
    "    player = Player()\n",
    "    total_collisions = 0\n",
    "\n",
    "    f = open(log_path, \"w\", encoding=\"utf-8\") if log_path else None\n",
    "\n",
    "    t0 = now_ms()\n",
    "    with ThreadPoolExecutor(max_workers=3) as pool:\n",
    "        for frame in range(n_frames):\n",
    "            player.y = float(jump_h if rng.random() < p_jump else 0.0)\n",
    "            p_snapshot = Player(player.x, player.y)\n",
    "            fut_upd = pool.submit(update_obstacles, x_curr, v, DT, x_next)\n",
    "            fut_col = pool.submit(collisions_count, x_curr, p_snapshot)\n",
    "            fut_ren = pool.submit(render_scene, frame, p_snapshot, x_curr, f)\n",
    "\n",
    "            fut_upd.result()\n",
    "            total_collisions += fut_col.result()\n",
    "            fut_ren.result()\n",
    "\n",
    "            x_curr, x_next = x_next, x_curr\n",
    "\n",
    "    t1 = now_ms()\n",
    "\n",
    "    if f:\n",
    "        f.write(f\"\\nColisiones totales: {total_collisions}\\n\")\n",
    "        f.close()\n",
    "\n",
    "    print(f\"Colisiones totales: {total_collisions}\")\n",
    "    if total_collisions < 5:\n",
    "        print(\"RESULTADO: SOBREVIVE\")\n",
    "    elif total_collisions > 5:\n",
    "        print(\"RESULTADO: MUERE\")\n",
    "    else:\n",
    "        print(\"RESULTADO: LIMITE (5 colisiones)\")\n",
    "    print(f\"Tiempo total simulacion: {t1 - t0:.3f} ms\")\n",
    "\n",
    "    return total_collisions, (t1 - t0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    N_FRAMES = 1000\n",
    "    N_OBS    = 200_000\n",
    "    JUMP_H   = 1.2\n",
    "    P_JUMP   = 0.25\n",
    "\n",
    "    x0 = (np.arange(N_OBS, dtype=np.float32) * 10.0)\n",
    "    v  = (-5.0 - np.arange(N_OBS, dtype=np.float32))\n",
    "    simulate_parallel(x0, v, N_FRAMES, JUMP_H, P_JUMP, seed=42, log_path=\"par_python.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a154c",
   "metadata": {},
   "source": [
    "# Comparativa de rendimiento: **paralelo en C** vs **paralelo en Python**\n",
    "\n",
    "**Datos medidos**\n",
    "\n",
    "| Implementación | Colisiones | Tiempo total (ms) | Frames/s procesados |\n",
    "|---|---:|---:|---:|\n",
    "| C (OpenMP, 3 hilos) | 673 | 48.709 | ≈ 20 530 |\n",
    "| Python (ThreadPool + NumPy, 3 hilos) | 689 | 117.746 | ≈ 8 493 |\n",
    "\n",
    "> Nota: la diferencia en colisiones proviene de la aleatoriedad y no afecta la comparación de tiempos.\n",
    "\n",
    "---\n",
    "\n",
    "## Métricas\n",
    "\n",
    "**Speedup de C respecto a Python**  \n",
    "$$\n",
    "S_{\\text{C}\\succ\\text{Py}} \\;=\\; \\frac{T_{\\text{Py}}}{T_{\\text{C}}}\n",
    "\\;=\\; \\frac{117.746}{48.709}\n",
    "\\;\\approx\\; 2.42\\times\n",
    "$$\n",
    "\n",
    "**Reducción relativa de tiempo al usar C**  \n",
    "$$\n",
    "\\Delta\\% \\;=\\; \\Bigl(1 - \\frac{T_{\\text{C}}}{T_{\\text{Py}}}\\Bigr)\\times 100\n",
    "\\;=\\; \\Bigl(1 - \\frac{48.709}{117.746}\\Bigr)\\times 100\n",
    "\\;\\approx\\; 58.63\\%\n",
    "$$\n",
    "\n",
    "**Throughput (frames procesados por segundo, no confundir con el FPS “jugable”)**\n",
    "\n",
    "- C:\n",
    "  $$\n",
    "  \\text{FPS}_{\\text{proc,C}} \\;=\\; \\frac{1000}{48.709/1000}\n",
    "  \\;\\approx\\; 20{,}531\\ \\text{frames/s}\n",
    "  $$\n",
    "- Python:\n",
    "  $$\n",
    "  \\text{FPS}_{\\text{proc,Py}} \\;=\\; \\frac{1000}{117.746/1000}\n",
    "  \\;\\approx\\; 8{,}493\\ \\text{frames/s}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusiones rápidas\n",
    "\n",
    "- **¿Qué tan más eficiente es en bajo nivel (C)?**  \n",
    "  En esta carga de trabajo C reduce el tiempo **≈ 58.6 %** respecto a Python.\n",
    "\n",
    "- **¿Qué tan más rápida es la implementación en C?**  \n",
    "  C es **≈ 2.42×** más rápida que la versión paralela equivalente en Python.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Por qué C gana aquí?\n",
    "\n",
    "- **Menor sobrecosto de ejecución.** C compila a código nativo y las secciones/loops de OpenMP tienen **overhead muy bajo** por frame.  \n",
    "- **Mejor explotación del hardware.** El compilador puede **autovectorizar** y aprovechar cachés y registros (SIMD) en los bucles sobre arreglos contiguos.\n",
    "- **Menos capas entre el código y la CPU.** En Python hay coste por:\n",
    "  - lanzar y sincronizar **3 tareas por frame** (3 000 *futures* en 1 000 frames),\n",
    "  - llamadas de funciones de alto nivel y creación de objetos efímeros,\n",
    "  - coordinación con el **GIL** (aunque NumPy lo libera en operaciones vectorizadas, la orquestación sigue en Python).\n",
    "\n",
    "El resultado práctico es que, aun con NumPy y threads, la versión en Python paga más administración por unidad de trabajo que la versión en C.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitaciones de trabajar en bajo nivel (C)\n",
    "\n",
    "- **Complejidad y tiempo de desarrollo.** Más código “boilerplate”, manejo manual de memoria y sincronización (riesgo de *data races* y *undefined behavior* si no se cuida).\n",
    "- **Mantenibilidad.** El código es menos expresivo y más difícil de modificar/extender que una solución en Python/NumPy.\n",
    "- **Portabilidad/Toolchain.** Dependencia de flags del compilador, versión de OpenMP, y particularidades de arquitectura.\n",
    "- **Depuración.** Bugs de concurrencia y de memoria son más sutiles y costosos de rastrear.\n",
    "\n",
    "**Resumen:** C ofrece **mayor rendimiento bruto** (≈ 2.42× en esta prueba) a costa de **mayor complejidad**. Python sacrifica velocidad por **productividad** y facilidad para iterar, aunque con NumPy + threads puede acercarse razonablemente cuando la carga es grande y vectorizable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
